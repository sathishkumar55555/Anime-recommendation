{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96e1d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T12:09:47.331329Z",
     "iopub.status.busy": "2023-06-12T12:09:47.330924Z",
     "iopub.status.idle": "2023-06-12T12:09:47.378742Z",
     "shell.execute_reply": "2023-06-12T12:09:47.376876Z",
     "shell.execute_reply.started": "2023-06-12T12:09:47.331297Z"
    },
    "papermill": {
     "duration": 0.016147,
     "end_time": "2023-07-28T06:08:56.728053",
     "exception": false,
     "start_time": "2023-07-28T06:08:56.711906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Notebook 2: Model Training\n",
    "\n",
    "Welcome to Notebook 2 of this recommendation system project!\n",
    "\n",
    "In Notebook 1, we performed exploratory data analysis (EDA), and visualized various aspects of the data to gain insights into our anime recommendation problem.\n",
    "\n",
    "In this notebook, we will focus on training the recommendation model. By separating the model training into a separate notebook, we ensure better memory management and organization of the project.\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "Note: If you haven't gone through Notebook 1 yet, I highly recommend you do so to understand the data and insights gained before moving on to the model training phase.\n",
    "\n",
    "[Click here to access Notebook 1: Exploratory Data Analysis and Dataset Preparation](https://www.kaggle.com/code/dbdmobile/anime-recommendation-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa28d022",
   "metadata": {
    "papermill": {
     "duration": 5.892295,
     "end_time": "2023-07-28T06:09:02.634794",
     "exception": false,
     "start_time": "2023-07-28T06:08:56.742499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944350fa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 43.953781,
     "end_time": "2023-07-28T06:09:46.602406",
     "exception": false,
     "start_time": "2023-07-28T06:09:02.648625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from wordcloud import WordCloud\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fb0487",
   "metadata": {
    "papermill": {
     "duration": 24.627243,
     "end_time": "2023-07-28T06:10:11.243271",
     "exception": false,
     "start_time": "2023-07-28T06:09:46.616028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Dataset: (24325191, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        1        21       9\n",
       "1        1        48       7\n",
       "2        1       320       5\n",
       "3        1        49       8\n",
       "4        1       304       8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv('../data/users-score-2023.csv', usecols=[\"user_id\",\"anime_id\",\"rating\"])\n",
    "print(\"Shape of the Dataset:\",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2296282",
   "metadata": {
    "papermill": {
     "duration": 4.594875,
     "end_time": "2023-07-28T06:10:15.853531",
     "exception": false,
     "start_time": "2023-07-28T06:10:11.258656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Rows:\n",
      "Empty DataFrame\n",
      "Columns: [user_id, anime_id, rating]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "duplicated_rows = df[df.duplicated()]\n",
    "print(\"Duplicated Rows:\")\n",
    "print(duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d80a721",
   "metadata": {
    "papermill": {
     "duration": 0.047536,
     "end_time": "2023-07-28T06:10:15.915084",
     "exception": false,
     "start_time": "2023-07-28T06:10:15.867548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 7.622930072779285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_score = np.mean(df['rating'])\n",
    "print('Average Score:', avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef072bd",
   "metadata": {
    "papermill": {
     "duration": 0.013813,
     "end_time": "2023-07-28T06:10:15.943426",
     "exception": false,
     "start_time": "2023-07-28T06:10:15.929613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049d4783",
   "metadata": {
    "papermill": {
     "duration": 0.371296,
     "end_time": "2023-07-28T06:10:16.328520",
     "exception": false,
     "start_time": "2023-07-28T06:10:15.957224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "df['scaled_score'] = scaler.fit_transform(df[['rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46187591",
   "metadata": {
    "papermill": {
     "duration": 12.355881,
     "end_time": "2023-07-28T06:10:28.698964",
     "exception": false,
     "start_time": "2023-07-28T06:10:16.343083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m user_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mLabelEncoder\u001b[49m()\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m user_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m num_users \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(user_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "user_encoder = LabelEncoder()\n",
    "df[\"user_encoded\"] = user_encoder.fit_transform(df[\"user_id\"])\n",
    "num_users = len(user_encoder.classes_)\n",
    "\n",
    "anime_encoder = LabelEncoder()\n",
    "df[\"anime_encoded\"] = anime_encoder.fit_transform(df[\"anime_id\"])\n",
    "num_animes = len(anime_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb17f4e",
   "metadata": {
    "papermill": {
     "duration": 0.016828,
     "end_time": "2023-07-28T06:10:28.732128",
     "exception": false,
     "start_time": "2023-07-28T06:10:28.715300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training (collaborative filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55585222",
   "metadata": {
    "papermill": {
     "duration": 4.716308,
     "end_time": "2023-07-28T06:10:33.464471",
     "exception": false,
     "start_time": "2023-07-28T06:10:28.748163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (24325191, 2)\n",
      "Shape of y: (24325191,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = shuffle(df, random_state=100)\n",
    "\n",
    "\n",
    "X = df[['user_encoded', 'anime_encoded']].values\n",
    "y = df[\"scaled_score\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a65dd08",
   "metadata": {
    "papermill": {
     "duration": 3.194518,
     "end_time": "2023-07-28T06:10:36.673253",
     "exception": false,
     "start_time": "2023-07-28T06:10:33.478735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 24315191\n",
      "Number of samples in the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "test_set_size = 10000 \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=73)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf88a1e9",
   "metadata": {
    "papermill": {
     "duration": 0.022594,
     "end_time": "2023-07-28T06:10:36.710025",
     "exception": false,
     "start_time": "2023-07-28T06:10:36.687431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b28eeb",
   "metadata": {
    "papermill": {
     "duration": 9.69542,
     "end_time": "2023-07-28T06:10:46.419966",
     "exception": false,
     "start_time": "2023-07-28T06:10:36.724546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1303\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1303\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1349\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1058\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1058\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1061\u001b[0m \n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:996\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 996\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:962\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    961\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:827\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    826\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    828\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Checking if TPU is initialized\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_TPU:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# If tpu is connected then start creating TPUStrategy\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     tpu_resolver \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_resolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTPUClusterResolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSumma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     tpu_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTPUStrategy(tpu_resolver)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu\\tpu_cluster_resolver.py:106\u001b[0m, in \u001b[0;36mTPUClusterResolver.connect\u001b[1;34m(tpu, zone, project)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             zone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m             project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes TPU and returns a TPUClusterResolver.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m  This API will connect to remote TPU cluster and initialize the TPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    NotFoundError: If no TPU devices found in eager mode.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m   resolver \u001b[38;5;241m=\u001b[39m \u001b[43mTPUClusterResolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remote  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m    108\u001b[0m   remote\u001b[38;5;241m.\u001b[39mconnect_to_cluster(resolver)\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu\\tpu_cluster_resolver.py:198\u001b[0m, in \u001b[0;36mTPUClusterResolver.__init__\u001b[1;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new TPUClusterResolver object.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mThe ClusterResolver will then use the parameters to query the Cloud TPU APIs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    Google Cloud environment.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;66;03m# Default Cloud environment\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_tpu_client \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m      \u001b[49m\u001b[43mzone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m      \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m      \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdiscovery_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscovery_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_tpu_client\u001b[38;5;241m.\u001b[39mname()\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;66;03m# Directly connected TPU environment\u001b[39;00m\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\tpu\\client\\client.py:177\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project \u001b[38;5;241m=\u001b[39m _as_text(project)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project \u001b[38;5;241m=\u001b[39m \u001b[43m_request_compute_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproject/project-id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zone:\n\u001b[0;32m    179\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zone \u001b[38;5;241m=\u001b[39m _as_text(zone)\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\tpu\\client\\client.py:82\u001b[0m, in \u001b[0;36m_request_compute_metadata\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_compute_metadata\u001b[39m(path):\n\u001b[0;32m     79\u001b[0m   req \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m     80\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/computeMetadata/v1/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (_gce_metadata_endpoint(), path),\n\u001b[0;32m     81\u001b[0m       headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetadata-Flavor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoogle\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 82\u001b[0m   resp \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _as_text(resp\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:1377\u001b[0m, in \u001b[0;36mHTTPHandler.http_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "\n",
    "USE_TPU = True\n",
    "\n",
    "\n",
    "if USE_TPU:\n",
    " \n",
    "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect(\"Summa\")\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
    "else:\n",
    "    !nvidia-smi\n",
    "    \n",
    "# Print the TensorFlow version\n",
    "tf_version = tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e631cd46",
   "metadata": {
    "papermill": {
     "duration": 2.254124,
     "end_time": "2023-07-28T06:10:48.691429",
     "exception": false,
     "start_time": "2023-07-28T06:10:46.437305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_encoded (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " anime_encoded (InputLayer)  [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 128)               3456422   ['user_encoded[0][0]']        \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " anime_embedding (Embedding  (None, 1, 128)               2112000   ['anime_encoded[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dot_product (Dot)           (None, 1, 1)                 0         ['user_embedding[0][0]',      \n",
      "                                                                     'anime_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1)                    0         ['dot_product[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   128       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    65        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36676417 (139.91 MB)\n",
      "Trainable params: 36676417 (139.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def RecommenderNet(num_users, num_animes, embedding_size=128):\n",
    "\n",
    "    user = Input(name='user_encoded', shape=[1])\n",
    "    user_embedding = Embedding(name='user_embedding', input_dim=num_users, output_dim=embedding_size)(user)\n",
    "\n",
    "    anime = Input(name='anime_encoded', shape=[1])\n",
    "    anime_embedding = Embedding(name='anime_embedding', input_dim=num_animes, output_dim=embedding_size)(anime)\n",
    "    \n",
    "\n",
    "    dot_product = Dot(name='dot_product', normalize=True, axes=2)([user_embedding, anime_embedding])\n",
    "    flattened = Flatten()(dot_product)\n",
    "    \n",
    "\n",
    "    dense = Dense(64, activation='relu')(flattened)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=[user, anime], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=[\"mae\", \"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = RecommenderNet(num_users, num_animes)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31d4252",
   "metadata": {
    "papermill": {
     "duration": 0.041421,
     "end_time": "2023-07-28T06:10:48.754830",
     "exception": false,
     "start_time": "2023-07-28T06:10:48.713409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import necessary callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "\n",
    "start_lr = 0.00001\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.00005\n",
    "batch_size = 10000\n",
    "\n",
    "\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < rampup_epochs:\n",
    "        return (max_lr - start_lr) / rampup_epochs * epoch + start_lr\n",
    "    elif epoch < rampup_epochs + sustain_epochs:\n",
    "        return max_lr\n",
    "    else:\n",
    "        return (max_lr - min_lr) * exp_decay**(epoch - rampup_epochs - sustain_epochs) + min_lr\n",
    "\n",
    "\n",
    "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n",
    "\n",
    "\n",
    "checkpoint_filepath = '/kaggle/working/myanimeweights.h5'\n",
    "\n",
    "\n",
    "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                    save_weights_only=True,\n",
    "                                    monitor='val_loss',\n",
    "                                    mode='min',\n",
    "                                    save_best_only=True)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "\n",
    "\n",
    "my_callbacks = [\n",
    "    model_checkpoints,\n",
    "    lr_callback,\n",
    "    early_stopping\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea24c7e5",
   "metadata": {
    "papermill": {
     "duration": 81.471222,
     "end_time": "2023-07-28T06:12:10.247133",
     "exception": false,
     "start_time": "2023-07-28T06:10:48.775911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 251/2432 [==>...........................] - ETA: 13:30 - loss: 0.6914 - mae: 0.2617 - mse: 0.0887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_callbacks\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\DWM_PROJECT\\anime-recommendation-system-master\\anime-recommendation-system-master\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    x=X_train_array,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_array, y_test),\n",
    "    callbacks=my_callbacks\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba06e3",
   "metadata": {
    "papermill": {
     "duration": 0.519031,
     "end_time": "2023-07-28T06:12:10.868751",
     "exception": false,
     "start_time": "2023-07-28T06:12:10.349720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(history.history[\"loss\"][0:-2])\n",
    "plt.plot(history.history[\"val_loss\"][0:-2])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c99c22",
   "metadata": {
    "papermill": {
     "duration": 0.101043,
     "end_time": "2023-07-28T06:12:11.070680",
     "exception": false,
     "start_time": "2023-07-28T06:12:10.969637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Recommendation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808b142",
   "metadata": {
    "papermill": {
     "duration": 0.340685,
     "end_time": "2023-07-28T06:12:11.512256",
     "exception": false,
     "start_time": "2023-07-28T06:12:11.171571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_weights(name, model):\n",
    "   \n",
    "    weight_layer = model.get_layer(name)\n",
    "    \n",
    " \n",
    "    weights = weight_layer.get_weights()[0]\n",
    "    \n",
    "\n",
    "    weights = weights / np.linalg.norm(weights, axis=1).reshape((-1, 1))\n",
    "    \n",
    "    return weights\n",
    "\n",
    "anime_weights = extract_weights('anime_embedding', model)\n",
    "\n",
    "user_weights = extract_weights('user_embedding', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33d4ec",
   "metadata": {
    "papermill": {
     "duration": 0.09984,
     "end_time": "2023-07-28T06:12:11.714098",
     "exception": false,
     "start_time": "2023-07-28T06:12:11.614258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Reading the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d089dcf",
   "metadata": {
    "papermill": {
     "duration": 0.607798,
     "end_time": "2023-07-28T06:12:12.423043",
     "exception": false,
     "start_time": "2023-07-28T06:12:11.815245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_anime=pd.read_csv('../data/anime-dataset-2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f4865",
   "metadata": {
    "papermill": {
     "duration": 0.101806,
     "end_time": "2023-07-28T06:12:12.627620",
     "exception": false,
     "start_time": "2023-07-28T06:12:12.525814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now I want my model to recommend only those animes that have been rated by at least a certain number of users, which I will set as the threshold. This threshold helps ensure that the recommended anime titles have received a sufficient number of ratings, indicating a certain level of popularity or user engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b26aa",
   "metadata": {
    "papermill": {
     "duration": 0.150399,
     "end_time": "2023-07-28T06:12:12.880153",
     "exception": false,
     "start_time": "2023-07-28T06:12:12.729754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "popularity_threshold = 50\n",
    "df_anime= df_anime.query('Members >= @popularity_threshold')\n",
    "print(df_anime.shape)\n",
    "df_anime.head(3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41021540",
   "metadata": {
    "papermill": {
     "duration": 0.114019,
     "end_time": "2023-07-28T06:12:13.102964",
     "exception": false,
     "start_time": "2023-07-28T06:12:12.988945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1: Item Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39459c6",
   "metadata": {
    "papermill": {
     "duration": 0.119554,
     "end_time": "2023-07-28T06:12:13.326244",
     "exception": false,
     "start_time": "2023-07-28T06:12:13.206690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar_animes(name, n=10, return_dist=False, neg=False):\n",
    "    try:\n",
    "        anime_row = df_anime[df_anime['Name'] == name].iloc[0]\n",
    "        index = anime_row['anime_id']\n",
    "        encoded_index = anime_encoder.transform([index])[0]\n",
    "        weights = anime_weights\n",
    "        dists = np.dot(weights, weights[encoded_index])\n",
    "        sorted_dists = np.argsort(dists)\n",
    "        n = n + 1            \n",
    "        if neg:\n",
    "            closest = sorted_dists[:n]\n",
    "        else:\n",
    "            closest = sorted_dists[-n:]\n",
    "        print('Animes closest to {}'.format(name))\n",
    "        if return_dist:\n",
    "            return dists, closest\n",
    "        \n",
    "        SimilarityArr = []\n",
    "        \n",
    "        for close in closest:\n",
    "            decoded_id = anime_encoder.inverse_transform([close])[0]\n",
    "            anime_frame = df_anime[df_anime['anime_id'] == decoded_id]\n",
    "            \n",
    "            anime_name = anime_frame['Name'].values[0]\n",
    "            english_name = anime_frame['English name'].values[0]\n",
    "            name = english_name if english_name != \"UNKNOWN\" else anime_name\n",
    "            genre = anime_frame['Genres'].values[0]\n",
    "            Synopsis = anime_frame['Synopsis'].values[0]\n",
    "            similarity = dists[close]\n",
    "            similarity = \"{:.2f}%\".format(similarity * 100)\n",
    "            SimilarityArr.append({\"Name\": name, \"Similarity\": similarity, \"Genres\": genre, \"Synopsis\":Synopsis})\n",
    "        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"Similarity\", ascending=False)\n",
    "        return Frame[Frame.Name != name]\n",
    "    except:\n",
    "        print('{} not found in Anime list'.format(name))\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd2363",
   "metadata": {
    "papermill": {
     "duration": 0.159493,
     "end_time": "2023-07-28T06:12:13.588234",
     "exception": false,
     "start_time": "2023-07-28T06:12:13.428741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_similar_animes('Tensei shitara Slime Datta Ken', n=5, neg=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbb115",
   "metadata": {
    "papermill": {
     "duration": 0.157302,
     "end_time": "2023-07-28T06:12:13.904486",
     "exception": false,
     "start_time": "2023-07-28T06:12:13.747184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_similar_animes('Shigatsu wa Kimi no Uso', n=5, neg=False) # Your Lie in April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64945df",
   "metadata": {
    "papermill": {
     "duration": 0.158074,
     "end_time": "2023-07-28T06:12:14.222417",
     "exception": false,
     "start_time": "2023-07-28T06:12:14.064343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_similar_animes('One Punch Man', n=5, neg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3434f",
   "metadata": {
    "papermill": {
     "duration": 0.159066,
     "end_time": "2023-07-28T06:12:14.542506",
     "exception": false,
     "start_time": "2023-07-28T06:12:14.383440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_similar_animes('Mushoku Tensei: Isekai Ittara Honki Dasu', n=5, neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4857bb00",
   "metadata": {
    "papermill": {
     "duration": 0.103728,
     "end_time": "2023-07-28T06:12:14.806423",
     "exception": false,
     "start_time": "2023-07-28T06:12:14.702695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2: User Based Recommendation\n",
    "#### (The user-based recommendation system is divided into three parts:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43717d",
   "metadata": {
    "papermill": {
     "duration": 0.110295,
     "end_time": "2023-07-28T06:12:15.023132",
     "exception": false,
     "start_time": "2023-07-28T06:12:14.912837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finding Similar Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f58f0d",
   "metadata": {
    "papermill": {
     "duration": 0.119567,
     "end_time": "2023-07-28T06:12:15.247199",
     "exception": false,
     "start_time": "2023-07-28T06:12:15.127632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar_users(item_input, n=10, return_dist=False, neg=False):\n",
    "    try:\n",
    "        index = item_input\n",
    "        encoded_index = user_encoder.transform([index])[0]\n",
    "        weights = user_weights\n",
    "        dists = np.dot(weights, weights[encoded_index])\n",
    "        sorted_dists = np.argsort(dists)\n",
    "        n = n + 1\n",
    "        \n",
    "        if neg:\n",
    "            closest = sorted_dists[:n]\n",
    "        else:\n",
    "            closest = sorted_dists[-n:]\n",
    "            \n",
    "        SimilarityArr = []\n",
    "        \n",
    "        for close in closest:\n",
    "            similarity = dists[close]\n",
    "            if isinstance(item_input, int):\n",
    "                decoded_id = user_encoder.inverse_transform([close])[0]\n",
    "                SimilarityArr.append({\"similar_users\": decoded_id, \"similarity\": similarity})\n",
    "        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", ascending=False)\n",
    "        return Frame\n",
    "    except:\n",
    "        print('Not Found in User list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2926d3",
   "metadata": {
    "papermill": {
     "duration": 1.297559,
     "end_time": "2023-07-28T06:12:16.653733",
     "exception": false,
     "start_time": "2023-07-28T06:12:15.356174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ratings_per_user = df.groupby('user_id').size()\n",
    "random_user = int(ratings_per_user[ratings_per_user < 500].sample(1, random_state=None).index[0])\n",
    "\n",
    "\n",
    "similar_users = find_similar_users(random_user, n=10, neg=False)\n",
    "similar_users = similar_users[similar_users.similarity > 0.4]\n",
    "similar_users = similar_users[similar_users.similar_users != random_user]\n",
    "similar_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5103ab1",
   "metadata": {
    "papermill": {
     "duration": 0.104311,
     "end_time": "2023-07-28T06:12:16.874584",
     "exception": false,
     "start_time": "2023-07-28T06:12:16.770273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## User Preferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65119377",
   "metadata": {
    "papermill": {
     "duration": 0.121015,
     "end_time": "2023-07-28T06:12:17.099493",
     "exception": false,
     "start_time": "2023-07-28T06:12:16.978478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def showWordCloud(all_genres):\n",
    "    genres_cloud = WordCloud(width=700, height=400, background_color='white', colormap='gnuplot').generate_from_frequencies(all_genres)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(genres_cloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def get_user_preferences(user_id, plot=False, verbose=0):\n",
    "    animes_watched_by_user = df[df['user_id'] == user_id]\n",
    "    \n",
    "    if animes_watched_by_user.empty:\n",
    "        print(\"User #{} has not watched any animes.\".format(user_id))\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    user_rating_percentile = np.percentile(animes_watched_by_user.rating, 75)\n",
    "    animes_watched_by_user = animes_watched_by_user[animes_watched_by_user.rating >= user_rating_percentile]\n",
    "    top_animes_user = (\n",
    "        animes_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "        .anime_id.values\n",
    "    )\n",
    "    \n",
    "    anime_df_rows = df_anime[df_anime[\"anime_id\"].isin(top_animes_user)]\n",
    "    anime_df_rows = anime_df_rows[[\"Name\", \"Genres\"]]\n",
    "    \n",
    "    if verbose != 0:\n",
    "        print(\"User \\033[1m{}\\033[0m has watched {} anime(s) with an average rating of {:.1f}/10\\n\".format(\n",
    "            user_id, len(animes_watched_by_user), animes_watched_by_user['rating'].mean()\n",
    "        ))\n",
    "        print('\\033[1m----- Preferred genres----- \\033[0m\\n')\n",
    "\n",
    "    if plot:\n",
    "        genres_list = []\n",
    "        for genres in anime_df_rows['Genres']:\n",
    "            if isinstance(genres, str):\n",
    "                for genre in genres.split(','):\n",
    "                    genres_list.append(genre.strip())\n",
    "\n",
    "        showWordCloud(dict(Counter(genres_list)))\n",
    "    \n",
    "    return anime_df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b4af1",
   "metadata": {
    "papermill": {
     "duration": 0.521516,
     "end_time": "2023-07-28T06:12:17.724454",
     "exception": false,
     "start_time": "2023-07-28T06:12:17.202938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_pref = get_user_preferences(random_user, plot=True, verbose=1)\n",
    "pd.DataFrame(user_pref).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ab263",
   "metadata": {
    "papermill": {
     "duration": 0.106274,
     "end_time": "2023-07-28T06:12:17.937994",
     "exception": false,
     "start_time": "2023-07-28T06:12:17.831720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Recommending Animes for a User\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e37c5",
   "metadata": {
    "papermill": {
     "duration": 0.122096,
     "end_time": "2023-07-28T06:12:18.165391",
     "exception": false,
     "start_time": "2023-07-28T06:12:18.043295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_recommended_animes(similar_users, user_pref, n=10):\n",
    "    recommended_animes = []\n",
    "    anime_list = []\n",
    "    \n",
    "    for user_id in similar_users.similar_users.values:\n",
    "        pref_list = get_user_preferences(int(user_id))\n",
    "        if not pref_list.empty:\n",
    "            pref_list = pref_list[~pref_list[\"Name\"].isin(user_pref[\"Name\"].values)]\n",
    "            anime_list.append(pref_list.Name.values)\n",
    "            \n",
    "    if len(anime_list) == 0:\n",
    "        print(\"No anime recommendations available for the given users.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    anime_list = pd.DataFrame(anime_list)\n",
    "    sorted_list = pd.DataFrame(pd.Series(anime_list.values.ravel()).value_counts()).head(n)\n",
    "\n",
    "    anime_count = df['anime_id'].value_counts()\n",
    "    \n",
    "    for i, anime_name in enumerate(sorted_list.index):\n",
    "        if isinstance(anime_name, str):\n",
    "            try:\n",
    "                anime_id = df_anime[df_anime.Name == anime_name].anime_id.values[0]\n",
    "                english_name = df_anime[df_anime['Name'] == anime_name]['English name'].values[0]\n",
    "                name = english_name if english_name != \"UNKNOWN\" else anime_name\n",
    "                genre = df_anime[df_anime.Name == anime_name].Genres.values[0]\n",
    "                Synopsis = df_anime[df_anime.Name == anime_name].Synopsis.values[0]\n",
    "                n_user_pref = anime_count.get(anime_id, 0)  \n",
    "                recommended_animes.append({\n",
    "                    \"n\": n_user_pref,\n",
    "                    \"anime_name\": anime_name, \n",
    "                    \"Genres\": genre, \n",
    "                    \"Synopsis\": Synopsis\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "    return pd.DataFrame(recommended_animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa7a9b",
   "metadata": {
    "papermill": {
     "duration": 0.880472,
     "end_time": "2023-07-28T06:12:19.151661",
     "exception": false,
     "start_time": "2023-07-28T06:12:18.271189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "recommended_animes = get_recommended_animes(similar_users, user_pref, n=10)\n",
    "\n",
    "print('\\n> Top recommendations for user: {}'.format(random_user))\n",
    "recommended_animes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e91fb",
   "metadata": {
    "papermill": {
     "duration": 0.106088,
     "end_time": "2023-07-28T06:12:19.364621",
     "exception": false,
     "start_time": "2023-07-28T06:12:19.258533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training (content-based filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00a22d",
   "metadata": {
    "papermill": {
     "duration": 7.856176,
     "end_time": "2023-07-28T06:12:27.327823",
     "exception": false,
     "start_time": "2023-07-28T06:12:19.471647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "\n",
    "tfidf_matrix_generator = tfidf.fit_transform((genre for genre in df_anime['Genres'].values.astype('U')))\n",
    "\n",
    "\n",
    "cosine_sim_sparse = linear_kernel(tfidf_matrix_generator, tfidf_matrix_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7096a",
   "metadata": {
    "papermill": {
     "duration": 0.106849,
     "end_time": "2023-07-28T06:12:27.542275",
     "exception": false,
     "start_time": "2023-07-28T06:12:27.435426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2: Content-Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873dca3",
   "metadata": {
    "papermill": {
     "duration": 0.119557,
     "end_time": "2023-07-28T06:12:27.769044",
     "exception": false,
     "start_time": "2023-07-28T06:12:27.649487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_recommendations(title, cosine_sim, df):\n",
    "    idx = df_anime[df_anime['Name'] == title].index[0]\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    valid_scores = [x for x in sim_scores if df_anime.iloc[x[0]]['Score'] != \"UNKNOWN\"]\n",
    "\n",
    "   \n",
    "    sorted_scores = sorted(valid_scores, key=lambda x: (x[1], df_anime.iloc[x[0]]['Score']), reverse=True)\n",
    "\n",
    "\n",
    "    top_animes = [x for x in sorted_scores if x[0] != idx][:10]\n",
    "\n",
    "    recommended_indices = [idx for idx, _ in top_animes]\n",
    "    recommended_animes = df_anime.iloc[recommended_indices][['Name', 'Genres', 'Score']]\n",
    "    return recommended_animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec5c9f",
   "metadata": {
    "papermill": {
     "duration": 4.712133,
     "end_time": "2023-07-28T06:12:32.587327",
     "exception": false,
     "start_time": "2023-07-28T06:12:27.875194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "anime_title = 'Kono Subarashii Sekai ni Shukufuku wo!'\n",
    "recommendations = get_recommendations(anime_title, cosine_sim_sparse, df_anime)\n",
    "print(f'Recommendations for \"{anime_title}\":')\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cad82",
   "metadata": {
    "papermill": {
     "duration": 4.823355,
     "end_time": "2023-07-28T06:12:37.518909",
     "exception": false,
     "start_time": "2023-07-28T06:12:32.695554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "anime_title = 'One Piece'\n",
    "recommendations = get_recommendations(anime_title, cosine_sim_sparse, df_anime)\n",
    "print(f'Recommendations for \"{anime_title}\":')\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1d072",
   "metadata": {
    "papermill": {
     "duration": 0.116104,
     "end_time": "2023-07-28T06:12:37.755881",
     "exception": false,
     "start_time": "2023-07-28T06:12:37.639777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 227.675184,
   "end_time": "2023-07-28T06:12:41.680415",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-28T06:08:54.005231",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
